{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from rbflayer import RBFLayer, InitCentersRandom\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://benalexkeen.com/feature-scaling-with-scikit-learn/\n",
    "# https://github.com/PetraVidnerova/rbf_keras/blob/master/rbflayer.py\n",
    "\n",
    "def load_dataset(is_normalize=True):\n",
    "    global dataset, labels\n",
    "    with open('OnlineNewsPopularity.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        next(reader) # skip the first row\n",
    "        temp = []\n",
    "        for idx, row in enumerate(reader):\n",
    "            temp.append(row[1:])\n",
    "        if is_normalize:\n",
    "            # it is important which type of normalization method you use\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            temp = scaler.fit_transform(temp)\n",
    "            print('Data is normalize')\n",
    "        else:\n",
    "            print('No normalize apply')\n",
    "        for idx, row in enumerate(temp):\n",
    "            slice_row = np.append(row[1:45], row[46:])\n",
    "            labels.append(row[45])\n",
    "            dataset.append(slice_row)\n",
    "    return np.array(dataset), np.array(labels).reshape(len(labels), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is normalize\n",
      "Dataset shape: (39644, 58), Labels: (39644, 1)\n",
      "x_train: (31715, 58), y_train: (31715, 1)\n",
      "x_test: (7929, 58), y_test: (7929, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset \n",
    "dataset = []\n",
    "labels = []\n",
    "# ori_dataset, ori_labels = load_dataset(is_normalize=False) \n",
    "dataset, labels = load_dataset(is_normalize=True)\n",
    "print('Dataset shape: {0}, Labels: {1}'.format(dataset.shape, labels.shape))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, random_state=42)\n",
    "print(\"x_train: {0}, y_train: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_test: {0}, y_test: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rbf_layer_11 (RBFLayer)      (None, 10)                590       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=1Cw45yNm6VA\n",
    "# build model\n",
    "# beta - controls the drop off of circle. higher the beta the faster the circle will drop off. This will then affect the \n",
    "#        size of the circle, faster drop off will cause new circle to form.\n",
    "#        (Drop of refers of gradient of circle, how smooth transit from circle area to non-circle area)\n",
    "model = Sequential()\n",
    "rbflayer = RBFLayer(10,\n",
    "                    initializer=InitCentersRandom(x_train), \n",
    "                    betas=1.5,\n",
    "                    input_shape=(58,))\n",
    "model.add(rbflayer)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31715 samples, validate on 7929 samples\n",
      "Epoch 1/50\n",
      "31715/31715 [==============================] - 3s 98us/step - loss: 0.0273 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01039, saving model to best_weights_rbf.h5\n",
      "Epoch 2/50\n",
      "31715/31715 [==============================] - 3s 94us/step - loss: 0.0089 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01039 to 0.00835, saving model to best_weights_rbf.h5\n",
      "Epoch 3/50\n",
      "31715/31715 [==============================] - 3s 81us/step - loss: 0.0078 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00835 to 0.00771, saving model to best_weights_rbf.h5\n",
      "Epoch 4/50\n",
      "31715/31715 [==============================] - 3s 82us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00771 to 0.00686, saving model to best_weights_rbf.h5\n",
      "Epoch 5/50\n",
      "31715/31715 [==============================] - 3s 88us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00686 to 0.00628, saving model to best_weights_rbf.h5\n",
      "Epoch 6/50\n",
      "31715/31715 [==============================] - 3s 82us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00628 to 0.00586, saving model to best_weights_rbf.h5\n",
      "Epoch 7/50\n",
      "31715/31715 [==============================] - 3s 101us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00586 to 0.00559, saving model to best_weights_rbf.h5\n",
      "Epoch 8/50\n",
      "31715/31715 [==============================] - 4s 115us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00559 to 0.00530, saving model to best_weights_rbf.h5\n",
      "Epoch 9/50\n",
      "31715/31715 [==============================] - 4s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/50\n",
      "31715/31715 [==============================] - 3s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00530 to 0.00522, saving model to best_weights_rbf.h5\n",
      "Epoch 11/50\n",
      "31715/31715 [==============================] - 4s 121us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00522 to 0.00507, saving model to best_weights_rbf.h5\n",
      "Epoch 12/50\n",
      "31715/31715 [==============================] - 4s 111us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00507 to 0.00494, saving model to best_weights_rbf.h5\n",
      "Epoch 13/50\n",
      "31715/31715 [==============================] - 3s 104us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00494 to 0.00468, saving model to best_weights_rbf.h5\n",
      "Epoch 14/50\n",
      "31715/31715 [==============================] - 3s 102us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00468 to 0.00464, saving model to best_weights_rbf.h5\n",
      "Epoch 15/50\n",
      "31715/31715 [==============================] - 3s 103us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00464 to 0.00452, saving model to best_weights_rbf.h5\n",
      "Epoch 16/50\n",
      "31715/31715 [==============================] - 3s 105us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00452 to 0.00449, saving model to best_weights_rbf.h5\n",
      "Epoch 17/50\n",
      "31715/31715 [==============================] - 3s 104us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00449 to 0.00433, saving model to best_weights_rbf.h5\n",
      "Epoch 18/50\n",
      "31715/31715 [==============================] - 3s 107us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00433 to 0.00424, saving model to best_weights_rbf.h5\n",
      "Epoch 19/50\n",
      "31715/31715 [==============================] - 3s 108us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00424 to 0.00410, saving model to best_weights_rbf.h5\n",
      "Epoch 20/50\n",
      "31715/31715 [==============================] - 3s 100us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00410 to 0.00402, saving model to best_weights_rbf.h5\n",
      "Epoch 21/50\n",
      "31715/31715 [==============================] - 3s 101us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/50\n",
      "31715/31715 [==============================] - 3s 101us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      "31715/31715 [==============================] - 4s 118us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/50\n",
      "31715/31715 [==============================] - 3s 109us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 25/50\n",
      "31715/31715 [==============================] - 3s 103us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00402 to 0.00374, saving model to best_weights_rbf.h5\n",
      "Epoch 26/50\n",
      "31715/31715 [==============================] - 3s 104us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00374 to 0.00374, saving model to best_weights_rbf.h5\n",
      "Epoch 27/50\n",
      "31715/31715 [==============================] - 4s 118us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00374 to 0.00369, saving model to best_weights_rbf.h5\n",
      "Epoch 28/50\n",
      "31715/31715 [==============================] - 4s 112us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00369 to 0.00369, saving model to best_weights_rbf.h5\n",
      "Epoch 29/50\n",
      "31715/31715 [==============================] - 3s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00369 to 0.00365, saving model to best_weights_rbf.h5\n",
      "Epoch 30/50\n",
      "31715/31715 [==============================] - 3s 106us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 31/50\n",
      "31715/31715 [==============================] - 4s 122us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00365 to 0.00364, saving model to best_weights_rbf.h5\n",
      "Epoch 32/50\n",
      "31715/31715 [==============================] - 3s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/50\n",
      "31715/31715 [==============================] - 3s 104us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00364 to 0.00363, saving model to best_weights_rbf.h5\n",
      "Epoch 34/50\n",
      "31715/31715 [==============================] - 3s 103us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00363 to 0.00363, saving model to best_weights_rbf.h5\n",
      "Epoch 35/50\n",
      "31715/31715 [==============================] - 3s 108us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/50\n",
      "31715/31715 [==============================] - 3s 103us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00363 to 0.00363, saving model to best_weights_rbf.h5\n",
      "Epoch 37/50\n",
      "31715/31715 [==============================] - 3s 108us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00363 to 0.00362, saving model to best_weights_rbf.h5\n",
      "Epoch 38/50\n",
      "31715/31715 [==============================] - 3s 103us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 39/50\n",
      "31715/31715 [==============================] - 3s 105us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00362 to 0.00362, saving model to best_weights_rbf.h5\n",
      "Epoch 40/50\n",
      "31715/31715 [==============================] - 3s 106us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/50\n",
      "31715/31715 [==============================] - 4s 121us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00362 to 0.00362, saving model to best_weights_rbf.h5\n",
      "Epoch 42/50\n",
      "31715/31715 [==============================] - 3s 104us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00362 to 0.00362, saving model to best_weights_rbf.h5\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31715/31715 [==============================] - 3s 100us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00362 to 0.00362, saving model to best_weights_rbf.h5\n",
      "Epoch 00043: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224213ceda0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training with callbacks\n",
    "saved_weights_name = 'best_weights_rbf.h5'\n",
    "\n",
    "# load weights if any\n",
    "if os.path.isfile(saved_weights_name):\n",
    "    model.load_weights(saved_weights_name)\n",
    "    print(\"Weights loaded: {0}\".format(saved_weights_name))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=0.0001,\n",
    "                           patience=10,\n",
    "                           mode='min',\n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint(saved_weights_name,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min',\n",
    "                             period=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=4,\n",
    "                              min_lr=0.00001,\n",
    "                              verbose=1)\n",
    "    \n",
    "model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[early_stop, checkpoint, reduce_lr],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7929/7929 [==============================] - 0s 42us/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-46722f16fa94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# showing results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0}: {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0}: {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# showing results\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"{0}: {1}\".format(model.metrics_names[0], round(scores[0], 6)))\n",
    "print(\"{0}: {1}\".format(model.metrics_names[1], round(scores[1], 6)))\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "y_pred = model.predict(x_test)\n",
    "var_score = explained_variance_score(y_pred, y_test)\n",
    "mean_abs_error = mean_absolute_error(y_pred, y_test)\n",
    "mean_sqare_log_error = mean_squared_log_error(y_pred, y_test)\n",
    "median_abs_error = median_absolute_error(y_pred, y_test)\n",
    "r2 = r2_score(y_pred, y_test)\n",
    "print('explained_variance_score: {0}'.format(round(var_score, 6)))\n",
    "print('mean_absolute_error: {0}'.format(round(mean_abs_error, 6)))\n",
    "print('mean_squared_log_error: {0}'.format(round(mean_sqare_log_error, 6)))\n",
    "print('median_absolute_error: {0}'.format(round(median_abs_error, 6)))\n",
    "print('r2_score: {0}'.format(round(r2, 6)))\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(y_pred[:100], label=\"predict\")\n",
    "plt.plot(y_test[:100], label=\"actual\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
