{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from rbflayer import RBFLayer, InitCentersRandom\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://benalexkeen.com/feature-scaling-with-scikit-learn/\n",
    "def load_dataset(is_normalize=True):\n",
    "    global dataset, labels\n",
    "    with open('OnlineNewsPopularity.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        next(reader) # skip the first row\n",
    "        temp = []\n",
    "        for idx, row in enumerate(reader):\n",
    "            temp.append(row[1:])\n",
    "        if is_normalize:\n",
    "            # it is important which type of normalization method you use\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            temp = scaler.fit_transform(temp)\n",
    "            print('Data is normalize')\n",
    "        else:\n",
    "            print('No normalize apply')\n",
    "        for idx, row in enumerate(temp):\n",
    "            slice_row = np.append(row[1:45], row[46:])\n",
    "            labels.append(row[45])\n",
    "            dataset.append(slice_row)\n",
    "    return np.array(dataset), np.array(labels).reshape(len(labels), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is normalize\n",
      "Dataset shape: (39644, 58), Labels: (39644, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset \n",
    "dataset = []\n",
    "labels = []\n",
    "# ori_dataset, ori_labels = load_dataset(is_normalize=False) \n",
    "dataset, labels = load_dataset(is_normalize=True)\n",
    "print('Dataset shape: {0}, Labels: {1}'.format(dataset.shape, labels.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
